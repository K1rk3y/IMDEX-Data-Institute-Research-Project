{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import timeit\n",
    "import datetime\n",
    "import pickle\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils import data, model_zoo\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utilities.loss import CrossEntropy2d\n",
    "from utilities.loss import CrossEntropyLoss2dPixelWiseWeighted\n",
    "import math\n",
    "\n",
    "from utilities import transformmasks\n",
    "from utilities import transformsgpu\n",
    "\n",
    "from utilities.voc_dataset import VOCDataSet\n",
    "from utilities.mcfs_dataset import MCFSDataSet\n",
    "\n",
    "from evaluateSSL import evaluate\n",
    "from utilities.class_balancing import ClassBalancing\n",
    "from utilities.feature_memory import *\n",
    "\n",
    "start = timeit.default_timer()\n",
    "start_writeable = datetime.datetime.now().strftime('%m-%d_%H-%M')\n",
    "\n",
    "class Learning_Rate_Object(object):\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.model = \"DeepLab\"\n",
    "        self.version = \"2\"\n",
    "        self.dataset = \"mcfs\"\n",
    "        self.deeplabv2 = True\n",
    "\n",
    "        # Training parameters\n",
    "        self.batch_size = 5\n",
    "        self.num_workers = 3\n",
    "        self.optimizer = \"SGD\"\n",
    "        self.momentum = 0.9\n",
    "        self.num_iterations = 150\n",
    "        self.learning_rate = 2e-4\n",
    "        self.lr_schedule = \"Poly\"\n",
    "        self.pretraining = \"COCO\"\n",
    "        self.lr_power = 0.9\n",
    "        self.weight_decay = 5e-4\n",
    "        self.use_teacher = True\n",
    "\n",
    "        # Data parameters\n",
    "        self.split_id = None\n",
    "        self.labeled_samples = 50\n",
    "        self.input_size = (512,512)\n",
    "        self.path = \"mcfs_dataset\"\n",
    "        self.num_classes = 18\n",
    "\n",
    "        # Miscellaneous\n",
    "        self.random_seed = 5555\n",
    "        self.ignore_label = 250\n",
    "\n",
    "        # Utility parameters\n",
    "        self.save_checkpoint_every = 200\n",
    "        self.checkpoint_dir = \"checkpoints/Deeplab\"\n",
    "        self.val_per_iter = 1000\n",
    "        self.save_best_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = Parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_class_to_class_learned_memory(model, features, class_labels, num_classes, memory):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        model: segmentation model that contains the self-attention MLPs for selecting the features\n",
    "        to take part in the contrastive learning optimization\n",
    "        features: Nx256  feature vectors for the contrastive learning (after applying the projection and prediction head)\n",
    "        class_labels: N corresponding class labels for every feature vector\n",
    "        num_classes: number of classesin the dataet\n",
    "        memory: memory bank [List]\n",
    "\n",
    "    Returns:\n",
    "        returns the contrastive loss between features vectors from [features] and from [memory] in a class-wise fashion.\n",
    "    \"\"\"\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        # get features of an specific class\n",
    "        mask_c = class_labels == c\n",
    "        features_c = features[mask_c,:]\n",
    "        memory_c = memory[c] # N, 256\n",
    "\n",
    "        # get the self-attention MLPs both for memory features vectors (projected vectors) and network feature vectors (predicted vectors)\n",
    "        selector = model.__getattr__('contrastive_class_selector_' + str(c))\n",
    "        selector_memory = model.__getattr__('contrastive_class_selector_memory' + str(c))\n",
    "\n",
    "        if memory_c is not None and features_c.shape[0] > 1 and memory_c.shape[0] > 1:\n",
    "\n",
    "            memory_c = torch.from_numpy(memory_c).cuda()\n",
    "\n",
    "            # L2 normalize vectors\n",
    "            memory_c = F.normalize(memory_c, dim=1) # N, 256\n",
    "            features_c_norm = F.normalize(features_c, dim=1) # M, 256\n",
    "\n",
    "            # compute similarity. All elements with all elements\n",
    "            similarities = torch.mm(features_c_norm, memory_c.transpose(1, 0))  # MxN\n",
    "            distances = 1 - similarities # values between [0, 2] where 0 means same vectors\n",
    "            # M (elements), N (memory)\n",
    "\n",
    "\n",
    "            # now weight every sample\n",
    "\n",
    "            learned_weights_features = selector(features_c.detach()) # detach for trainability\n",
    "            learned_weights_features_memory = selector_memory(memory_c)\n",
    "\n",
    "            # self-atention in the memory featuers-axis and on the learning contrsative featuers-axis\n",
    "            learned_weights_features = torch.sigmoid(learned_weights_features)\n",
    "            rescaled_weights = (learned_weights_features.shape[0] / learned_weights_features.sum(dim=0)) * learned_weights_features\n",
    "            rescaled_weights = rescaled_weights.repeat(1, distances.shape[1])\n",
    "            distances = distances * rescaled_weights\n",
    "\n",
    "\n",
    "            learned_weights_features_memory = torch.sigmoid(learned_weights_features_memory)\n",
    "            learned_weights_features_memory = learned_weights_features_memory.permute(1, 0)\n",
    "            rescaled_weights_memory = (learned_weights_features_memory.shape[0] / learned_weights_features_memory.sum(dim=0)) * learned_weights_features_memory\n",
    "            rescaled_weights_memory = rescaled_weights_memory.repeat(distances.shape[0], 1)\n",
    "            distances = distances * rescaled_weights_memory\n",
    "\n",
    "\n",
    "            loss = loss + distances.mean()\n",
    "\n",
    "    return loss / num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_loss(v, mask):\n",
    "    \"\"\"\n",
    "        Entropy loss for probabilistic prediction vectors\n",
    "        input: batch_size x channels x h x w\n",
    "        output: batch_size x 1 x h x w\n",
    "    \"\"\"\n",
    "    assert v.dim() == 4\n",
    "    n, c, h, w = v.size()\n",
    "\n",
    "    loss_image = torch.mul(v, torch.log2(v + 1e-30))\n",
    "    loss_image = torch.sum(loss_image, dim=1)\n",
    "    loss_image = mask.float().squeeze(1) * loss_image\n",
    "\n",
    "\n",
    "    percentage_valid_points = torch.mean(mask.float())\n",
    "\n",
    "    return -torch.sum(loss_image) / (n * h * w * np.log2(c) * percentage_valid_points)\n",
    "\n",
    "def lr_poly(base_lr, iter, max_iter, power):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        base_lr: initial learning rate\n",
    "        iter: current iteration\n",
    "        max_iter: maximum number of iterations\n",
    "        power: power value for polynomial decay\n",
    "\n",
    "    Returns: the updated learning rate with polynomial decay\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return base_lr * ((1 - float(iter) / float(max_iter)) ** (power))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, i_iter):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        optimizer: pytorch optimizer\n",
    "        i_iter: current iteration\n",
    "\n",
    "    Returns: sets learning rate with poliynomial decay\n",
    "\n",
    "    \"\"\"\n",
    "    lr = lr_poly(para.learning_rate, i_iter, para.num_iterations, para.lr_power)\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    if len(optimizer.param_groups) > 1:\n",
    "        optimizer.param_groups[1]['lr'] = lr\n",
    "\n",
    "\n",
    "def sigmoid_ramp_up(iter, max_iter):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        iter: current iteration\n",
    "        max_iter: maximum number of iterations to perform the rampup\n",
    "\n",
    "    Returns:\n",
    "        returns 1 if iter >= max_iter\n",
    "        returns [0,1] incrementally from 0 to max_iters if iter < max_iter\n",
    "\n",
    "    \"\"\"\n",
    "    if iter >= max_iter:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.exp(- 5 * (1 - float(iter) / float(max_iter)) ** 2)\n",
    "\n",
    "def update_BN_weak_unlabeled_data(model, norm_func, batch_size, loader, iters=1000):\n",
    "    iterator = iter(loader)\n",
    "    model.train()\n",
    "    for _ in range(iters):\n",
    "        ''' UNLABELED SAMPLES '''\n",
    "        try:\n",
    "            batch = next(iterator)\n",
    "            if batch[0].shape[0] != batch_size:\n",
    "                batch = next(iterator)\n",
    "        except:\n",
    "            iterator = iter(loader)\n",
    "            batch = next(iterator)\n",
    "\n",
    "        # Unlabeled\n",
    "        unlabeled_images, _, _, _, _ = batch\n",
    "        unlabeled_images = unlabeled_images.cuda()\n",
    "\n",
    "        # Create pseudolabels\n",
    "        _, _ = model(norm_func(unlabeled_images, para.dataset), return_features=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "def augmentationTransform(parameters, data=None, target=None, probs=None, jitter_vale=0.4, min_sigma=0.2, max_sigma=2., ignore_label=255):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        parameters: dictionary with the augmentation configuration\n",
    "        data: BxCxWxH input data to augment\n",
    "        target: BxWxH labels to augment\n",
    "        probs: BxWxH probability map to augment\n",
    "        jitter_vale:  jitter augmentation value\n",
    "        min_sigma: min sigma value for blur\n",
    "        max_sigma: max sigma value for blur\n",
    "        ignore_label: value for ignore class\n",
    "\n",
    "    Returns:\n",
    "            augmented data, target, probs\n",
    "    \"\"\"\n",
    "    assert ((data is not None) or (target is not None))\n",
    "    if \"Mix\" in parameters:\n",
    "        data, target, probs = transformsgpu.mix(mask=parameters[\"Mix\"], data=data, target=target, probs=probs)\n",
    "\n",
    "    if \"RandomScaleCrop\" in parameters:\n",
    "        data, target, probs = transformsgpu.random_scale_crop(scale=parameters[\"RandomScaleCrop\"], data=data,\n",
    "                                                              target=target, probs=probs, ignore_label=ignore_label)\n",
    "    if \"flip\" in parameters:\n",
    "        data, target, probs = transformsgpu.flip(flip=parameters[\"flip\"], data=data, target=target, probs=probs)\n",
    "\n",
    "    if \"ColorJitter\" in parameters:\n",
    "        data, target, probs = transformsgpu.colorJitter(colorJitter=parameters[\"ColorJitter\"], data=data, target=target,\n",
    "                                                        probs=probs, s=jitter_vale)\n",
    "    if \"GaussianBlur\" in parameters:\n",
    "        data, target, probs = transformsgpu.gaussian_blur(blur=parameters[\"GaussianBlur\"], data=data, target=target,\n",
    "                                                          probs=probs, min_sigma=min_sigma, max_sigma=max_sigma)\n",
    "\n",
    "    if \"Grayscale\" in parameters:\n",
    "        data, target, probs = transformsgpu.grayscale(grayscale=parameters[\"Grayscale\"], data=data, target=target,\n",
    "                                                      probs=probs)\n",
    "    if \"Solarize\" in parameters:\n",
    "        data, target, probs = transformsgpu.solarize(solarize=parameters[\"Solarize\"], data=data, target=target,\n",
    "                                                     probs=probs)\n",
    "\n",
    "    return data, target, probs\n",
    "\n",
    "\n",
    "def _save_checkpoint(iteration, model, optimizer, save_best=False, overwrite=True):\n",
    "    \"\"\"\n",
    "    Saves the current checkpoint\n",
    "\n",
    "    Args:\n",
    "        iteration: current iteration [int]\n",
    "        model: segmentation model\n",
    "        optimizer: pytorch optimizer\n",
    "        config: configuration\n",
    "        save_best: Boolean: whether to sae only if best metric\n",
    "        overwrite: whether to overwrite if ther is an existing checkpoint\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'iteration': iteration,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    checkpoint['model'] = model.state_dict()\n",
    "\n",
    "    if save_best:\n",
    "        filename = os.path.join(para.checkpoint_dir, f'best_model.pth')\n",
    "        torch.save(checkpoint, filename)\n",
    "        print(f'\\nSaving a checkpoint: {filename} ...')\n",
    "        print(\"Saving current best model: best_model.pth\")\n",
    "    else:\n",
    "        filename = os.path.join(para.checkpoint_dir, f'checkpoint-iter{iteration}.pth')\n",
    "        print(f'\\nSaving a checkpoint: {filename} ...')\n",
    "        torch.save(checkpoint, filename)\n",
    "        if overwrite:\n",
    "            try:\n",
    "                os.remove(os.path.join(para.checkpoint_dir, f'checkpoint-iter{iteration - para.save_checkpoint_every}.pth'))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "def create_ema_model(model, net_class):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        model: segmentation model to copy parameters from\n",
    "        net_class: segmentation model class\n",
    "\n",
    "    Returns: Segmentation model from [net_class] with same parameters than [model]\n",
    "\n",
    "    \"\"\"\n",
    "    ema_model = net_class(num_classes=para.num_classes)\n",
    "\n",
    "    for param in ema_model.parameters():\n",
    "        param.detach_()\n",
    "    mp = list(model.parameters())\n",
    "    mcp = list(ema_model.parameters())\n",
    "    n = len(mp)\n",
    "    for i in range(0, n):\n",
    "        mcp[i].data[:] = mp[i].data[:].clone()\n",
    "\n",
    "    return ema_model\n",
    "\n",
    "def update_ema_variables(ema_model, model, alpha_teacher, iteration):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        ema_model: model to update\n",
    "        model: model from which to update parameters\n",
    "        alpha_teacher: value for weighting the ema_model\n",
    "        iteration: current iteration\n",
    "\n",
    "    Returns: ema_model, with parameters updated follwoing the exponential moving average of [model]\n",
    "\n",
    "    \"\"\"\n",
    "    # Use the \"true\" average until the exponential average is more correct\n",
    "    alpha_teacher = min(1 - 1 / (iteration*10 + 1), alpha_teacher)\n",
    "    for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
    "        ema_param.data[:] = alpha_teacher * ema_param[:].data[:] + (1 - alpha_teacher) * param[:].data[:]\n",
    "\n",
    "    return ema_model\n",
    "\n",
    "def augment_samples(images, labels, probs, do_classmix, batch_size, ignore_label, weak = False):\n",
    "    \"\"\"\n",
    "    Perform data augmentation\n",
    "\n",
    "    Args:\n",
    "        images: BxCxWxH images to augment\n",
    "        labels:  BxWxH labels to augment\n",
    "        probs:  BxWxH probability maps to augment\n",
    "        do_classmix: whether to apply classmix augmentation\n",
    "        batch_size: batch size\n",
    "        ignore_label: ignore class value\n",
    "        weak: whether to perform weak or strong augmentation\n",
    "\n",
    "    Returns:\n",
    "        augmented data, augmented labels, augmented probs\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if do_classmix:\n",
    "        # ClassMix: Get mask for image A\n",
    "        for image_i in range(batch_size):  # for each image\n",
    "            classes = torch.unique(labels[image_i])  # get unique classes in pseudolabel A\n",
    "            nclasses = classes.shape[0]\n",
    "\n",
    "            # remove ignore class\n",
    "            if ignore_label in classes and len(classes) > 1 and nclasses > 1:\n",
    "                classes = classes[classes != ignore_label]\n",
    "                nclasses = nclasses - 1\n",
    "\n",
    "            if para.dataset == 'pascal_voc':  # if voc dataaset, remove class 0, background\n",
    "                if 0 in classes and len(classes) > 1 and nclasses > 1:\n",
    "                    classes = classes[classes != 0]\n",
    "                    nclasses = nclasses - 1\n",
    "\n",
    "            # pick half of the classes randomly\n",
    "            classes = (classes[torch.Tensor(\n",
    "                np.random.choice(nclasses, int(((nclasses - nclasses % 2) / 2) + 1), replace=False)).long()]).cuda()\n",
    "\n",
    "            # acumulate masks\n",
    "            if image_i == 0:\n",
    "                MixMask = transformmasks.generate_class_mask(labels[image_i], classes).unsqueeze(0).cuda()\n",
    "            else:\n",
    "                MixMask = torch.cat(\n",
    "                    (MixMask, transformmasks.generate_class_mask(labels[image_i], classes).unsqueeze(0).cuda()))\n",
    "\n",
    "\n",
    "        params = {\"Mix\": MixMask}\n",
    "    else:\n",
    "        params = {}\n",
    "\n",
    "    if weak:\n",
    "        params[\"flip\"] = random.random() < 0.5\n",
    "        params[\"ColorJitter\"] = random.random() < 0.2\n",
    "        params[\"GaussianBlur\"] = random.random() < 0.\n",
    "        params[\"Grayscale\"] = random.random() < 0.0\n",
    "        params[\"Solarize\"] = random.random() < 0.0\n",
    "        if random.random() < 0.5:\n",
    "            scale = random.uniform(0.75, 1.75)\n",
    "        else:\n",
    "            scale = 1\n",
    "        params[\"RandomScaleCrop\"] = scale\n",
    "\n",
    "        # Apply strong augmentations to unlabeled images\n",
    "        image_aug, labels_aug, probs_aug = augmentationTransform(params,\n",
    "                                                                 data=images, target=labels,\n",
    "                                                                 probs=probs, jitter_vale=0.125,\n",
    "                                                                 min_sigma=0.1, max_sigma=1.5,\n",
    "                                                                 ignore_label=ignore_label)\n",
    "    else:\n",
    "        params[\"flip\"] = random.random() < 0.5\n",
    "        params[\"ColorJitter\"] = random.random() < 0.8\n",
    "        params[\"GaussianBlur\"] = random.random() < 0.2\n",
    "        params[\"Grayscale\"] = random.random() < 0.0\n",
    "        params[\"Solarize\"] = random.random() < 0.0\n",
    "        if random.random() < 0.80:\n",
    "            scale = random.uniform(0.75, 1.75)\n",
    "        else:\n",
    "            scale = 1\n",
    "        params[\"RandomScaleCrop\"] = scale\n",
    "\n",
    "        # Apply strong augmentations to unlabeled images\n",
    "        image_aug, labels_aug, probs_aug = augmentationTransform(params,\n",
    "                                                                 data=images, target=labels,\n",
    "                                                                 probs=probs, jitter_vale=0.25,\n",
    "                                                                 min_sigma=0.1, max_sigma=1.5,\n",
    "                                                                 ignore_label=ignore_label)\n",
    "\n",
    "    return image_aug, labels_aug, probs_aug, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    cudnn.enabled = True\n",
    "    torch.manual_seed(para.random_seed)\n",
    "    torch.cuda.manual_seed(para.random_seed)\n",
    "    np.random.seed(para.random_seed)\n",
    "    random.seed(para.random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    if para.pretraining == 'COCO': # depending the pretraining, normalize with bgr or rgb\n",
    "        from utilities.transformsgpu import normalize_bgr as normalize\n",
    "    else:\n",
    "        from utilities.transformsgpu import normalize_rgb as normalize\n",
    "\n",
    "    batch_size_unlabeled = int(para.batch_size / 2) # because of augmentation anchoring, 2 augmentations per sample\n",
    "    batch_size_labeled = int(para.batch_size * 1)\n",
    "    assert batch_size_unlabeled >= 2, \"batch size should be higher than 2\"\n",
    "    assert batch_size_labeled >= 2, \"batch size should be higher than 2\"\n",
    "    RAMP_UP_ITERS = 2000 # iterations until contrastive and self-training are taken into account\n",
    "\n",
    "    # DATASETS / LOADERS\n",
    "    if para.dataset == 'pascal_voc':\n",
    "        train_dataset = VOCDataSet(para.path, crop_size=para.input_size, scale=False, mirror=False, pretraining=para.pretraining)\n",
    "\n",
    "    elif para.dataset == 'mcfs':\n",
    "        train_dataset = MCFSDataSet(para.path, crop_size=para.input_size, scale=False, mirror=False)\n",
    "\n",
    "    train_dataset_size = len(train_dataset)\n",
    "    print('dataset size: ', train_dataset_size)\n",
    "\n",
    "    partial_size = para.labeled_samples\n",
    "    print('Training on number of samples:', partial_size)\n",
    "\n",
    "    # class weighting  taken unlabeled data into acount in an incremental fashion.\n",
    "    class_weights_curr = ClassBalancing(labeled_iters=int(para.labeled_samples / batch_size_labeled),\n",
    "                                                  unlabeled_iters=int(\n",
    "                                                      (train_dataset_size - para.labeled_samples) / batch_size_unlabeled),\n",
    "                                                  n_classes=para.num_classes)\n",
    "    # Memory Bank\n",
    "    feature_memory = FeatureMemory(num_samples=para.labeled_samples, dataset=para.dataset, memory_per_class=256, feature_size=256, n_classes=para.num_classes)\n",
    "\n",
    "    # select the partition\n",
    "    if para.split_id is not None:\n",
    "        train_ids = pickle.load(open(para.split_id, 'rb'))\n",
    "        print('loading train ids from {}'.format(para.split_id))\n",
    "    else:\n",
    "        train_ids = np.arange(train_dataset_size)\n",
    "        np.random.shuffle(train_ids)\n",
    "\n",
    "    # Samplers for labeled data\n",
    "    train_sampler = data.sampler.SubsetRandomSampler(train_ids[:partial_size])\n",
    "    trainloader = data.DataLoader(train_dataset,\n",
    "                                  batch_size=batch_size_labeled, sampler=train_sampler, num_workers=para.num_workers,\n",
    "                                  pin_memory=True)\n",
    "    trainloader_iter = iter(trainloader)\n",
    "\n",
    "    # Samplers for unlabeled data\n",
    "    train_remain_sampler = data.sampler.SubsetRandomSampler(train_ids[partial_size:])\n",
    "    trainloader_remain = data.DataLoader(train_dataset,\n",
    "                                         batch_size=batch_size_unlabeled, sampler=train_remain_sampler,\n",
    "                                         num_workers=para.num_workers, pin_memory=True)\n",
    "    trainloader_remain_iter = iter(trainloader_remain)\n",
    "\n",
    "    # supervised loss\n",
    "    supervised_loss = CrossEntropy2d(ignore_label=para.ignore_label).cuda()\n",
    "\n",
    "    ''' Deeplab model '''\n",
    "    # Define network\n",
    "    if para.deeplabv2:\n",
    "        if para.pretraining == 'COCO': # coco and imagenet resnet architectures differ a little, just on how to do the stride\n",
    "            from utilities.deeplabv2 import Res_Deeplab\n",
    "        else: # imagenet pretrained (more modern modification)\n",
    "            from utilities.deeplabv2_imagenet import Res_Deeplab\n",
    "\n",
    "        # load pretrained parameters\n",
    "        if para.pretraining == 'COCO':\n",
    "            saved_state_dict = model_zoo.load_url('http://vllab1.ucmerced.edu/~whung/adv-semi-seg/resnet101COCO-41f33a49.pth') # COCO pretraining\n",
    "        else:\n",
    "            saved_state_dict = model_zoo.load_url('https://download.pytorch.org/models/resnet101-5d3b4d8f.pth') # imagenet pretrainning\n",
    "\n",
    "    else:\n",
    "        from utilities.deeplabv3 import Res_Deeplab50 as Res_Deeplab\n",
    "        saved_state_dict = model_zoo.load_url('https://download.pytorch.org/models/resnet50-19c8e357.pth') # imagenet pretrainning\n",
    "\n",
    "    # create network\n",
    "    model = Res_Deeplab(num_classes=para.num_classes)\n",
    "\n",
    "    # Copy loaded parameters to model\n",
    "    new_params = model.state_dict().copy()\n",
    "    for name, param in new_params.items():\n",
    "        if name in saved_state_dict and param.size() == saved_state_dict[name].size():\n",
    "            new_params[name].copy_(saved_state_dict[name])\n",
    "    model.load_state_dict(new_params)\n",
    "\n",
    "\n",
    "    # Optimizer for segmentation network\n",
    "    learning_rate_object = Learning_Rate_Object(para.learning_rate)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.optim_parameters(learning_rate_object),\n",
    "                          lr=para.learning_rate, momentum=para.momentum, weight_decay=para.weight_decay)\n",
    "\n",
    "    ema_model = create_ema_model(model, Res_Deeplab)\n",
    "    ema_model.train()\n",
    "    ema_model = ema_model.cuda()\n",
    "    model.train()\n",
    "    model = model.cuda()\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # pickle.dump(train_ids, open(os.path.join(para.checkpoint_dir, 'train_split.pkl'), 'wb'))\n",
    "\n",
    "    interp = nn.Upsample(size=(para.input_size[0], para.input_size[1]), mode='bilinear', align_corners=True)\n",
    "\n",
    "    epochs_since_start = 0\n",
    "    start_iteration = 0\n",
    "    best_mIoU = 0  # best metric while training\n",
    "    iters_without_improve = 0\n",
    "\n",
    "    # TRAINING\n",
    "    for i_iter in range(start_iteration, para.num_iterations):\n",
    "        model.train()  # set mode to training\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_l_value = 0.\n",
    "        adjust_learning_rate(optimizer, i_iter)\n",
    "\n",
    "        ''' LABELED SAMPLES '''\n",
    "        # Get batch\n",
    "        try:\n",
    "            batch = next(trainloader_iter)\n",
    "            if batch[0].shape[0] != batch_size_labeled:\n",
    "                batch = next(trainloader_iter)\n",
    "        except:  # finish epoch, rebuild the iterator\n",
    "            epochs_since_start = epochs_since_start + 1\n",
    "            # print('Epochs since start: ',epochs_since_start)\n",
    "            trainloader_iter = iter(trainloader)\n",
    "            batch = next(trainloader_iter)\n",
    "\n",
    "        images, labels, _, _, _ = batch\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        ''' UNLABELED SAMPLES '''\n",
    "        try:\n",
    "            batch_remain = next(trainloader_remain_iter)\n",
    "            if batch_remain[0].shape[0] != batch_size_unlabeled:\n",
    "                batch_remain = next(trainloader_remain_iter)\n",
    "        except:\n",
    "            trainloader_remain_iter = iter(trainloader_remain)\n",
    "            batch_remain = next(trainloader_remain_iter)\n",
    "\n",
    "        # Unlabeled\n",
    "        unlabeled_images, _, _, _, _ = batch_remain\n",
    "        unlabeled_images = unlabeled_images.cuda()\n",
    "\n",
    "        # Create pseudolabels\n",
    "        with torch.no_grad():\n",
    "            if para.use_teacher:\n",
    "                logits_u_w, features_weak_unlabeled = ema_model(normalize(unlabeled_images, para.dataset), return_features=True)\n",
    "            else:\n",
    "                model.eval()\n",
    "                logits_u_w, features_weak_unlabeled = model(normalize(unlabeled_images, para.dataset), return_features=True)\n",
    "                model.train()\n",
    "\n",
    "            logits_u_w = interp(logits_u_w).detach()  # prediction unlabeled\n",
    "            softmax_u_w = torch.softmax(logits_u_w, dim=1)\n",
    "            max_probs, pseudo_label = torch.max(softmax_u_w, dim=1)  # Get pseudolabels\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        images_aug, labels_aug, _, _ = augment_samples(images, labels, None, random.random()  < 0.2, batch_size_labeled, para.ignore_label, weak=True)\n",
    "\n",
    "        '''\n",
    "        UNLABELED DATA\n",
    "        '''\n",
    "        unlabeled_images_aug1, pseudo_label1, max_probs1, unlabeled_aug1_params = augment_samples(unlabeled_images,\n",
    "                                                                                                  pseudo_label,\n",
    "                                                                                                  max_probs,\n",
    "                                                                                                  i_iter > RAMP_UP_ITERS and random.random() < 0.75,\n",
    "                                                                                                  batch_size_unlabeled,\n",
    "                                                                                                  para.ignore_label)\n",
    "\n",
    "\n",
    "        unlabeled_images_aug2, pseudo_label2, max_probs2, unlabeled_aug2_params = augment_samples(unlabeled_images,\n",
    "                                                                                                  pseudo_label,\n",
    "                                                                                                  max_probs,\n",
    "                                                                                                  i_iter > RAMP_UP_ITERS and random.random() < 0.75,\n",
    "                                                                                                  batch_size_unlabeled,\n",
    "                                                                                                  para.ignore_label)\n",
    "        \n",
    "        target_tensor = pseudo_label1  # replace with your actual target tensor name\n",
    "        print(\"pseudo_label1 tensor shape:\", target_tensor.shape)\n",
    "        print(\"Unique values in pseudo_label1:\", torch.unique(target_tensor).tolist())\n",
    "\n",
    "        # concatenate two augmentations of unlabeled data\n",
    "        joined_unlabeled = torch.cat((unlabeled_images_aug1, unlabeled_images_aug2), dim=0)\n",
    "        joined_pseudolabels = torch.cat((pseudo_label1, pseudo_label2), dim=0)\n",
    "        joined_maxprobs = torch.cat((max_probs1, max_probs2), dim=0)\n",
    "\n",
    "        pred_joined_unlabeled, features_joined_unlabeled = model(normalize(joined_unlabeled, para.dataset), return_features=True)\n",
    "        pred_joined_unlabeled = interp(pred_joined_unlabeled)\n",
    "\n",
    "        # labeled data\n",
    "        labeled_pred, labeled_features = model(normalize(images_aug, para.dataset), return_features=True)\n",
    "        labeled_pred = interp(labeled_pred)\n",
    "\n",
    "        # apply class balance for cityspcaes dataset\n",
    "        class_weights = torch.from_numpy(np.ones((para.num_classes))).cuda()\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        # SUPERVISED SEGMENTATION\n",
    "        labeled_loss = supervised_loss(labeled_pred, labels_aug, weight=class_weights.float())\n",
    "        loss = loss + labeled_loss\n",
    "\n",
    "        # SELF-SUPERVISED SEGMENTATION\n",
    "        print(\"class_weights shape:\", class_weights.shape)\n",
    "        unlabeled_loss = CrossEntropyLoss2dPixelWiseWeighted(ignore_index=para.ignore_label, weight=class_weights.float()).cuda() #\n",
    "\n",
    "        # Pseudo-label weighting\n",
    "        print(\"joined_maxprobs shape:\", joined_maxprobs.shape)\n",
    "        print(\"joined_maxprobs stats:\", \n",
    "            \"min:\", joined_maxprobs.min().item(),\n",
    "            \"max:\", joined_maxprobs.max().item(),\n",
    "            \"has_nan:\", torch.isnan(joined_maxprobs).any().item())\n",
    "        pixelWiseWeight = sigmoid_ramp_up(i_iter, RAMP_UP_ITERS) * torch.ones(joined_maxprobs.shape).cuda()\n",
    "        print(\"pixelWiseWeight shape:\", pixelWiseWeight.shape)\n",
    "        pixelWiseWeight = pixelWiseWeight * torch.pow(joined_maxprobs.detach(), 6)\n",
    "\n",
    "        # Pseudo-label loss\n",
    "        target_tensor = joined_pseudolabels  # replace with your actual target tensor name\n",
    "        print(\"Target tensor shape:\", target_tensor.shape)\n",
    "        print(\"Unique values in target:\", torch.unique(target_tensor).tolist())\n",
    "        print(\"Min target value:\", target_tensor.min().item())\n",
    "        print(\"Max target value:\", target_tensor.max().item())\n",
    "        loss_ce_unlabeled = unlabeled_loss(pred_joined_unlabeled, joined_pseudolabels, pixelWiseWeight)\n",
    "\n",
    "        loss = loss + loss_ce_unlabeled\n",
    "\n",
    "        # entropy loss\n",
    "        valid_mask = (joined_pseudolabels != para.ignore_label).unsqueeze(1)\n",
    "        loss = loss + entropy_loss(torch.nn.functional.softmax(pred_joined_unlabeled, dim=1), valid_mask) * 0.01\n",
    "\n",
    "        # CONTRASTIVE LEARNING\n",
    "        if i_iter > RAMP_UP_ITERS - 1000:\n",
    "            # Build Memory Bank 1000 iters before starting to do contrastive\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Get feature vectors from labeled images with EMA model\n",
    "                if para.use_teacher:\n",
    "                    labeled_pred_ema, labeled_features_ema = ema_model(normalize(images_aug, para.dataset), return_features=True)\n",
    "                else:\n",
    "                    model.eval()\n",
    "                    labeled_pred_ema, labeled_features_ema = model(normalize(images_aug, para.dataset), return_features=True)\n",
    "                    model.train()\n",
    "\n",
    "                labeled_pred_ema = interp(labeled_pred_ema)\n",
    "                probability_prediction_ema, label_prediction_ema = torch.max(torch.softmax(labeled_pred_ema, dim=1),dim=1)  # Get pseudolabels\n",
    "\n",
    "            # Resize labels, predictions and probabilities,  to feature map resolution\n",
    "            labels_down = nn.functional.interpolate(labels_aug.float().unsqueeze(1), size=(labeled_features_ema.shape[2], labeled_features_ema.shape[3]),\n",
    "                                                    mode='nearest').squeeze(1)\n",
    "            label_prediction_down = nn.functional.interpolate(label_prediction_ema.float().unsqueeze(1), size=(labeled_features_ema.shape[2], labeled_features_ema.shape[3]),\n",
    "                                                    mode='nearest').squeeze(1)\n",
    "            probability_prediction_down = nn.functional.interpolate(probability_prediction_ema.float().unsqueeze(1), size=(labeled_features_ema.shape[2], labeled_features_ema.shape[3]),\n",
    "                                                    mode='nearest').squeeze(1)\n",
    "\n",
    "\n",
    "            # get mask where the labeled predictions are correct and have a confidence higher than 0.95\n",
    "            mask_prediction_correctly = ((label_prediction_down == labels_down).float() * (probability_prediction_down > 0.95).float()).bool()\n",
    "\n",
    "            # Apply the filter mask to the features and its labels\n",
    "            labeled_features_correct = labeled_features_ema.permute(0, 2, 3, 1)\n",
    "            labels_down_correct = labels_down[mask_prediction_correctly]\n",
    "            labeled_features_correct = labeled_features_correct[mask_prediction_correctly, ...]\n",
    "\n",
    "            # get projected features\n",
    "            with torch.no_grad():\n",
    "                if para.use_teacher:\n",
    "                    proj_labeled_features_correct = ema_model.projection_head(labeled_features_correct)\n",
    "                else:\n",
    "                    model.eval()\n",
    "                    proj_labeled_features_correct = model.projection_head(labeled_features_correct)\n",
    "                    model.train()\n",
    "            # updated memory bank\n",
    "            feature_memory.add_features_from_sample_learned(ema_model, proj_labeled_features_correct, labels_down_correct, batch_size_labeled)\n",
    "\n",
    "\n",
    "\n",
    "        if i_iter > RAMP_UP_ITERS:\n",
    "            '''\n",
    "            CONTRASTIVE LEARNING ON LABELED DATA. Force features from labeled samples, to be similar to other features from the same class (which also leads to good predictions\n",
    "            '''\n",
    "            # mask features that do not have ignore label in the labels (zero-padding because of data augmentation like resize/crop)\n",
    "            mask_prediction_correctly = (labels_down != para.ignore_label)\n",
    "\n",
    "            labeled_features_all = labeled_features.permute(0, 2, 3, 1)\n",
    "            labels_down_all = labels_down[mask_prediction_correctly]\n",
    "            labeled_features_all = labeled_features_all[mask_prediction_correctly, ...]\n",
    "\n",
    "            # get predicted features\n",
    "            proj_labeled_features_all = model.projection_head(labeled_features_all)\n",
    "            pred_labeled_features_all = model.prediction_head(proj_labeled_features_all)\n",
    "\n",
    "            # Apply contrastive learning loss\n",
    "            loss_contr_labeled = contrastive_class_to_class_learned_memory(model, pred_labeled_features_all, labels_down_all,\n",
    "                                para.num_classes, feature_memory.memory)\n",
    "\n",
    "            loss = loss + loss_contr_labeled * 0.1\n",
    "\n",
    "\n",
    "            '''\n",
    "            CONTRASTIVE LEARNING ON UNLABELED DATA. align unlabeled features to labeled features\n",
    "            '''\n",
    "            joined_pseudolabels_down = nn.functional.interpolate(joined_pseudolabels.float().unsqueeze(1),\n",
    "                                                    size=(features_joined_unlabeled.shape[2], features_joined_unlabeled.shape[3]),\n",
    "                                                    mode='nearest').squeeze(1)\n",
    "\n",
    "            # mask features that do not have ignore label in the labels (zero-padding because of data augmentation like resize/crop)\n",
    "            mask = (joined_pseudolabels_down != para.ignore_label)\n",
    "\n",
    "            features_joined_unlabeled = features_joined_unlabeled.permute(0, 2, 3, 1)\n",
    "            features_joined_unlabeled = features_joined_unlabeled[mask, ...]\n",
    "            joined_pseudolabels_down = joined_pseudolabels_down[mask]\n",
    "\n",
    "            # get predicted features\n",
    "            proj_feat_unlabeled = model.projection_head(features_joined_unlabeled)\n",
    "            pred_feat_unlabeled = model.prediction_head(proj_feat_unlabeled)\n",
    "\n",
    "            # Apply contrastive learning loss\n",
    "            loss_contr_unlabeled = contrastive_class_to_class_learned_memory(model, pred_feat_unlabeled, joined_pseudolabels_down,\n",
    "                                para.num_classes, feature_memory.memory)\n",
    "\n",
    "            loss = loss + loss_contr_unlabeled * 0.1\n",
    "\n",
    "        print(\"STEP: \", i_iter, \" LOSS: \", loss)\n",
    "        loss_l_value += loss.item()\n",
    "\n",
    "        # optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        m = 1 - (1 - 0.995) * (math.cos(math.pi * i_iter / para.num_iterations) + 1) / 2\n",
    "        ema_model = update_ema_variables(ema_model=ema_model, model=model, alpha_teacher=m, iteration=i_iter)\n",
    "\n",
    "\n",
    "        if i_iter % para.save_checkpoint_every == 0 and i_iter != 0:\n",
    "            if para.save_teacher:\n",
    "                _save_checkpoint(i_iter, ema_model, optimizer)\n",
    "            else:\n",
    "                _save_checkpoint(i_iter, model, optimizer)\n",
    "\n",
    "        if i_iter % para.val_per_iter == 0 and i_iter != 0:\n",
    "            print('iter = {0:6d}/{1:6d}'.format(i_iter, para.num_iterations))\n",
    "\n",
    "            model.eval()\n",
    "            mIoU, eval_loss = evaluate(model, para.dataset, para.path, deeplabv2=para.deeplabv2, ignore_label=para.ignore_label, save_dir=para.checkpoint_dir, pretraining=para.pretraining, show_visualizations=False)\n",
    "            model.train()\n",
    "\n",
    "            if mIoU > best_mIoU:\n",
    "                best_mIoU = mIoU\n",
    "                if para.save_teacher:\n",
    "                    _save_checkpoint(i_iter, ema_model, optimizer, save_best=True)\n",
    "                else:\n",
    "                    _save_checkpoint(i_iter, model, optimizer, save_best=True)\n",
    "                iters_without_improve = 0\n",
    "            else:\n",
    "                iters_without_improve += para.val_per_iter\n",
    "\n",
    "            '''\n",
    "            if the performance has not improve in N iterations, try to reload best model to optimize again with a lower LR\n",
    "            Simulating an iterative training'''\n",
    "            if iters_without_improve > para.num_iterations/5.:\n",
    "                print('Re-loading a previous best model')\n",
    "                checkpoint = torch.load(os.path.join(para.checkpoint_dir, f'best_model.pth'))\n",
    "                model.load_state_dict(checkpoint['model'])\n",
    "                ema_model = create_ema_model(model, Res_Deeplab)\n",
    "                ema_model.train()\n",
    "                ema_model = ema_model.cuda()\n",
    "                model.train()\n",
    "                model = model.cuda()\n",
    "                iters_without_improve = 0 # reset timer\n",
    "\n",
    "    _save_checkpoint(para.num_iterations, model, optimizer)\n",
    "\n",
    "    # FINISH TRAINING, evaluate again\n",
    "    model.eval()\n",
    "    mIoU, eval_loss = evaluate(model, para.dataset, para.path, deeplabv2=para.deeplabv2, ignore_label=para.ignore_label, save_dir=para.checkpoint_dir, pretraining=para.pretraining, show_visualizations=False)\n",
    "    model.train()\n",
    "\n",
    "    if mIoU > best_mIoU and para.save_best_model:\n",
    "        best_mIoU = mIoU\n",
    "        _save_checkpoint(i_iter, model, optimizer, save_best=True)\n",
    "\n",
    "    # TRY IMPROVING BEST MODEL WITH EMA MODEL OR UPDATING BN STATS\n",
    "\n",
    "    # Load best model\n",
    "    checkpoint = torch.load(os.path.join(para.checkpoint_dir, f'best_model.pth'))\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model = model.cuda()\n",
    "\n",
    "    model = update_BN_weak_unlabeled_data(model, normalize, batch_size_unlabeled, trainloader_remain)\n",
    "    model.eval()\n",
    "    mIoU, eval_loss = evaluate(model, para.dataset, para.path, deeplabv2=para.deeplabv2, ignore_label=para.ignore_label, save_dir=para.checkpoint_dir, pretraining=para.pretraining, show_visualizations=False)\n",
    "    if mIoU > best_mIoU and para.save_best_model:\n",
    "        best_mIoU = mIoU\n",
    "        _save_checkpoint(i_iter, model, optimizer, save_best=True)\n",
    "\n",
    "    print('BEST MIOU')\n",
    "    print(best_mIoU)\n",
    "\n",
    "    end = timeit.default_timer()\n",
    "    print('Total time: ' + str(end - start) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_pixel_coordinates(dataset, data_path, pretraining='COCO'):\n",
    "    \"\"\"\n",
    "    Generate a mapping of class IDs to pixel coordinates for each image in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained segmentation model\n",
    "        dataset (str): Dataset name ('pascal_voc' or 'mcfs')\n",
    "        data_path (str): Path to the dataset\n",
    "        pretraining (str): Pretraining dataset used ('COCO' or other)\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries, each containing image name and class coordinate mappings\n",
    "    \"\"\"\n",
    "\n",
    "    if para.deeplabv2:\n",
    "        if para.pretraining == 'COCO': # coco and imagenet resnet architectures differ a little, just on how to do the stride\n",
    "            from utilities.deeplabv2 import Res_Deeplab\n",
    "        else: # imagenet pretrained (more modern modification)\n",
    "            from utilities.deeplabv2_imagenet import Res_Deeplab\n",
    "\n",
    "        # load pretrained parameters\n",
    "        if para.pretraining == 'COCO':\n",
    "            saved_state_dict = model_zoo.load_url('http://vllab1.ucmerced.edu/~whung/adv-semi-seg/resnet101COCO-41f33a49.pth') # COCO pretraining\n",
    "        else:\n",
    "            saved_state_dict = model_zoo.load_url('https://download.pytorch.org/models/resnet101-5d3b4d8f.pth') # imagenet pretrainning\n",
    "\n",
    "    else:\n",
    "        from utilities.deeplabv3 import Res_Deeplab50 as Res_Deeplab\n",
    "        saved_state_dict = model_zoo.load_url('https://download.pytorch.org/models/resnet50-19c8e357.pth') # imagenet pretrainning\n",
    "\n",
    "    # create network\n",
    "    model = Res_Deeplab(num_classes=para.num_classes)\n",
    "\n",
    "    # Copy loaded parameters to model\n",
    "    new_params = model.state_dict().copy()\n",
    "    for name, param in new_params.items():\n",
    "        if name in saved_state_dict and param.size() == saved_state_dict[name].size():\n",
    "            new_params[name].copy_(saved_state_dict[name])\n",
    "    model.load_state_dict(new_params)\n",
    "\n",
    "    checkpoint = torch.load(os.path.join(para.checkpoint_dir, f'best_model.pth'))\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model = model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    # Set up normalization based on pretraining\n",
    "    if pretraining == 'COCO':\n",
    "        from utilities.transformsgpu import normalize_bgr as normalize\n",
    "    else:\n",
    "        from utilities.transformsgpu import normalize_rgb as normalize\n",
    "    \n",
    "    # Set up dataset\n",
    "    if dataset == 'pascal_voc':\n",
    "        test_dataset = VOCDataSet(data_path, split=\"val\", scale=False, mirror=False, pretraining=pretraining)\n",
    "    elif dataset == 'mcfs':\n",
    "        test_dataset = MCFSDataSet(data_path, split=\"val\", scale=False, mirror=False, pretraining=pretraining)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset: {dataset}\")\n",
    "        \n",
    "    testloader = data.DataLoader(test_dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "    results = []\n",
    "    \n",
    "    for index, batch in enumerate(testloader):\n",
    "        image, label, size, name, _ = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Get model prediction\n",
    "            interp = torch.nn.Upsample(size=(label.shape[1], label.shape[2]), mode='bilinear', align_corners=True)\n",
    "            output = model(normalize(Variable(image).cuda(), dataset))\n",
    "            output = interp(output)\n",
    "            \n",
    "            # Convert output to numpy array and get class predictions\n",
    "            output = output.cpu().data[0].numpy()\n",
    "            prediction = np.argmax(output, axis=0)\n",
    "            \n",
    "            # Create coordinate mapping for each class\n",
    "            class_coordinates = {}\n",
    "            height, width = prediction.shape\n",
    "            \n",
    "            # Iterate through the prediction mask to collect coordinates\n",
    "            for y in range(height):\n",
    "                for x in range(width):\n",
    "                    class_id = int(prediction[y, x])\n",
    "                    if class_id not in class_coordinates:\n",
    "                        class_coordinates[class_id] = []\n",
    "                    class_coordinates[class_id].append((x, y))\n",
    "            \n",
    "            # Store results for this image\n",
    "            results.append({\n",
    "                'image_name': name[0],\n",
    "                'coordinates': class_coordinates,\n",
    "                'image_size': (height, width)\n",
    "            })\n",
    "        \n",
    "        if (index + 1) % 10 == 0:\n",
    "            print(f'Processed {index + 1} images')\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46211/676315510.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(os.path.join(para.checkpoint_dir, f'best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 valid image-label pairs\n",
      "Processed 10 images\n",
      "Processed 20 images\n",
      "Processed 30 images\n",
      "Processed 40 images\n",
      "Processed 50 images\n",
      "Processed 60 images\n",
      "Processed 70 images\n",
      "Processed 80 images\n",
      "Processed 90 images\n",
      "Processed 100 images\n",
      "Class 0: 694088 pixels\n",
      "Class 1: 203305 pixels\n",
      "Class 13: 107 pixels\n",
      "Class 2: 513 pixels\n",
      "Class 15: 2887 pixels\n",
      "Class 16: 216 pixels\n",
      "Class 10: 11084 pixels\n",
      "Class 14: 614 pixels\n",
      "Class 5: 1370 pixels\n",
      "Class 6: 5194 pixels\n",
      "Class 17: 1502 pixels\n",
      "Class 8: 307 pixels\n",
      "Class 12: 23 pixels\n",
      "Class 9: 116 pixels\n",
      "Class 7: 254 pixels\n",
      "Class 4: 20 pixels\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "coordinate_maps = class_pixel_coordinates(\"mcfs\", \"mcfs_dataset\")\n",
    "\n",
    "for image_data in coordinate_maps:\n",
    "    for class_id, coords in image_data['coordinates'].items():\n",
    "        print(f\"Class {class_id}: {len(coords)} pixels\")\n",
    "    print(\"-----\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
